% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/EM_lctmc_2x2.R
\name{EM_lctmc_2x2}
\alias{EM_lctmc_2x2}
\title{EM-algorithm for a latent CTMC model}
\usage{
EM_lctmc_2x2(
  theta.init,
  theta.names,
  par_constraint,
  K,
  df,
  df.Xmat,
  df.Wmat,
  df.dt,
  EM.maxit,
  ELL_diff.tol,
  LPY_diff.tol,
  par_diff.tol,
  L_BFGS_B.ctrl,
  parallel_optim,
  MyModelName
)
}
\arguments{
\item{theta.init}{a named numeric vector, where the names are the model parameter names. Use this argument to specified the initial values for the EM algorithm}

\item{theta.names}{a list of character vectors, where each element of this list is a character vector specifying the names of model parameters. \cr
Note: model parameters grouped within the same element will be simultaneously optimized during the ECM step.}

\item{par_constraint}{a named numeric vector to indicate which parameter is constrained. Set equal to NULL for unconstrained model. \cr
For example, \code{c(alpha1.1 = 0)} constraints the parameter 'alpha1.1' to be a constant 0. \strong{NOTE:} Current version of the code will \emph{only} work with constrains equal to 0.}

\item{K}{an integer scalar. Used to determine the number of latent classes the model is fitting.}

\item{df}{a data frame object holding the binary row-wise transition indicator variables}

\item{df.Xmat}{a matrix object housing the covariates that affect the CTMC portion of the model. This matrix should have the same number of rows as the data frame object, \code{df}}

\item{df.Wmat}{a matrix object housing the covariates that affect the latent classification part of the model. This matrix should have number of rows equal to unique number of individuals in the data frame object, \code{df}}

\item{df.dt}{a numeric vector housing the length of time interval between observations. This vector's length should be equal to number of rows in the data frame object, \code{df}}

\item{EM.maxit}{a numeric scalar. Use this argument to specify the maximum iteration the EM algorithm.
Setting this variable too large will cause longer run time if optimal point is harder to reach. However, too low will lead to non-optimal points.
Typically, somewhere between 100-300 iterations is adequate depending on the problem.}

\item{ELL_diff.tol}{a numeric scalar that is greater than 0. This is the tolerance value for the expected conditional log-likelihood. \cr
The smaller this value, the more precise the estimate, however the longer run time will be needed.}

\item{LPY_diff.tol}{a numeric scalar that is greater than 0. This is the tolerance value for the log observed likelihood, \eqn{log(P(Y))}. \cr
The smaller this value, the more precise the estimate, however the longer run time will be needed.}

\item{par_diff.tol}{a numeric scalar that is greater than 0. This is the tolerance value for the changes in model parameter by iterations. \cr
The smaller this value, the more precise the estimate, however the longer run time will be needed.}

\item{L_BFGS_B.ctrl}{a list object holding the control parameter for the L-BFGS optimization algorithm. \cr
Note that the L-BFGS is utilized during each ECM step, where we attempt to maximize the conditional expected log-likelihood function with respect to a subset of the model parameters. \cr
This list object should contain \strong{three} elements (see \code{?optim} for more info): \cr
(1) \code{fnscale} is a negative real number, this is used to scale the value of the objective function. Setting it to negative implies that a maximization is being performed. \cr
(2) \code{maxit} is the maximum number of iterations the algorithm will run before terminating \cr
(3) \code{factr} is tolerance parameter for algorithm convergence, the smaller the value, the better accracy but also longer run time}

\item{parallel_optim}{a list object telling the function whether parallel process should be used for the Step 2 of the initial value generation. \cr
The list should contain \strong{two} elements: \cr
(1) \code{run} a logical scalar, if TRUE then this function will use parallel processing. If FALSE, then the \code{cl} argument is ignored. \cr
(2) \code{cl} is an object obtained from the \code{parallel} package, for example \cr \code{cl = parallel::makeCluster(spec = 2)}}

\item{MyModelName}{a character scalar. Gives the current model fitting process a name. This name will be used when the function is logging the algorithm progress.}
}
\value{
A list object containing as many elements as the number of EM iteration that were performed
Each element is a sub list object with the following elements:
\itemize{
\item \strong{iter} is a numeric scalar, indicating the count of current iteration
\item \strong{pars_value} is a named numeric vector for current iteration's estimated parameter values
\item \strong{ELL_value} is a numeric scalar for the current iteration's expected conditional log-likelihood evaluated at \code{pars_value}
\item \strong{LPY_value} is a numeric scalar for the current iteration's \eqn{log(P(Y))} evaluated at \code{pars_value}
\item \strong{par_diff.max} is a numeric scalar comparing previous iteration's \code{pars_value} and current iteration's \code{pars_value}. This value is maximum difference between the iterations. \cr
This is one of the values to evaluate EM algorithm's convergence. When \code{par_diff.max} < \code{par_diff.tol}, one of the convergence criteria is met.
\item \strong{ELL_diff} is a numeric scalar comparing previous iteration and current iteration's expected conditional log-likelihood. \cr
This is one of the values to evaluate EM algorithm's convergence. When \code{ELL_diff} < \code{ELL_diff.tol}, one of the convergence criteria is met.
\item \strong{LPY_diff} is a numeric scalar comparing previous iteration and current iteration's \eqn{log(P(Y))}. \cr
This is one of the values to evaluate EM algorithm's convergence. When \code{LPY_diff} < \code{LPY_diff.tol}, one of the convergence criteria is met.
\item \strong{time_at_finish} is a 'difftime' object telling the time from start of algorithm to current iteration
}
}
\description{
The EM algorithm attempts to maximize the likelihood by iteratively optimize the conditional expected log-likelihood.
This optimization approach is used to obtained the MLE of the latent class CTMC model.
Convergence for the EM algorithm is met when the improvement in the conditional expected log-likelihood does not improve further
}
\note{
This function is actually the Expected Conditional Maximization (ECM) algorithm.
within each EM step, subsets of parameters are optimize one set at a time, the number of ECM step is determined by \code{theta.names}. \cr
Note that step 2 of \code{gen_inits_lctmc_2x2()} will likely produce a good approximation of the MLE. so when the EM algorithm requires large number of iterations
it is likely that we are getting a non-global optimal point.
}
\examples{
## TO BE ADDED ##
}
