% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lctmc_3x3.R
\name{lctmc_3x3}
\alias{lctmc_3x3}
\title{Fit a Latent Class CTMC model (3x3)}
\usage{
lctmc_3x3(
  data = data.frame(),
  dt_scale = c(),
  x_scale = c(),
  w_scale = c(),
  K = integer(),
  X_names = c(),
  W_names = c(),
  par_constraint,
  N_sub,
  pct_keep = c(),
  parallelize = FALSE,
  which_step1 = c("100\%", "best"),
  theta.names = list(),
  EM_controls = list(),
  optim_controls = list(),
  test_if_global_optim = list(test = FALSE, true_params = NA),
  parallel_optim = list(run = FALSE, cl = NA),
  MyModelName = "lctmc_3x3"
)
}
\arguments{
\item{data}{a data frame object with data stored in long-format}

\item{dt_scale}{a named numeric scalar. It is a scaling parameter for observation time intervals. \cr
For example, \code{dt_scale = c(dt = 1/10)} would converts a time unit from 10 to 1.}

\item{x_scale}{a named numeric vector. It is a scaling parameters for covariates that affect the CTMC process. \cr
For example, \code{x_scale = c(x0 = 1, x1 = 1/5, x2 = 1)} would convert x1 from 10 to 2.}

\item{w_scale}{a named numeric vector. It is a scaling parameters for covariates that affect the latent class component of the model  \cr
For example, \code{w_scale = c(w0 = 1, x1 = 1/3, x2 = 1)} would convert w1 from 12 to 4.}

\item{K}{an integer scalar. Use this variable to tell the function how many latent classes there should be. \cr
Note that the number of latent classes will affect the number of parameters in the model.}

\item{X_names}{a named character vector. Hosting the names of covariates for the CTMC model. It should be a column in \code{data}. Best set to x0, x1, x2 to avoid errors}

\item{W_names}{a named character vector. Hosting names of covariates for the latent class component. It should be a column in \code{data}. Best set to w0, w1, w2 to avoid errors}

\item{par_constraint}{a named numeric vector to indicate which parameter is constrained. Set equal to NULL for unconstrained model. \cr
For example, \code{c(alpha1.1 = 0)} constraints the parameter 'alpha1.1' to be a constant 0. \strong{NOTE:} Current version of the code will \emph{only} work with constrains equal to 0.}

\item{N_sub}{a numeric scalar. This is used for step 1 of initial value generation where the algorithm fits a traditional CTMC model for each individual. \cr
Fitting the model for \emph{all} individuals might have long run time without improvement in the accuracy of the estimation.
Thus, using this argument to set a maximum number of individuals to use for the initial value generation could save some computation time.}

\item{pct_keep}{a numeric vector where each element of the vector ranges from 0 to 1 (ideally, 0.50 to 0.95).
This argument controls what percentage of the individual effect should be used for the K-means algorithm for initial value generation. The algorithm will consider all percentages specified in this vector. \cr
For example, for \code{pct_keep = c(0.5)}, after individuals effects are estimated, only the 25th to 75th percentile are used for the K-Means algorithm to obtain cluster level estimates. \cr
Additionally, note that the threshold "1" is always appended to \code{pct_keep}, so it will always at least consider the 100\% case.}

\item{parallelize}{a logical scalar. Set to TRUE if we want the for-loop for the individual-wise CTMC to be parallelized}

\item{which_step1}{a character scalar. Either "100\%" or "best". The former will use 100\% of the individual CTCM effects to perform the K-means algorithm. \cr
The latter will compute the \eqn{log(P(Y))} value for all possible K-means result and use the thetas that yields the largest \eqn{log(P(Y))}.}

\item{theta.names}{a list of parameter names, e.g., \code{list(c("alpha1.1", "alpha2.1"), c("beta0.21_1", "beta1.21_1", "beta2.21_1"))}. \cr
This argument is used to determine the number of ECM sub-steps. Parameters within the same element of the list will be optimized together as a group. \cr
User can use the function \code{gen_theta_names()} to generate this with ease.}

\item{EM_controls}{a list object holding the arguments to tune the EM algorithm.
The following elements are necessary for running the algorithm: \cr
(1) \code{maxit} a numeric scalar. This specifies the max number of EM iterations \cr
(2) \code{ELL_tol} a numeric scalar. This is the tolerance of the conditional expected log likelihood \cr
(3) \code{LPY_tol} a numeric scalar. This is the tolerance of observed log likelihood, \eqn{log(P(Y))} \cr
(4) \code{par_tol} a numeric scalar. This is the tolerance of parameter changes per EM iteration \cr \cr
Note that for all 3 tolerance parameters, the smaller the value, the more accurate the estimate will be. But it will also lead to longer computation time.}

\item{optim_controls}{a list object holding the arguments to control the L-BFGS optimization at each ECM step.
The following elements are necessary for running the algorithm: \cr
(1) \code{fnscale} a numeric scalar. This value scales the objective function. Additionally, its sign determines whether the algorithm is performing a maximization or minimization task. \cr
(2) \code{maxit} a numeric scalar. This value specifies the max number of L-BFGS iterations. \cr
(3) \code{factr} a numeric scalar. This value controls the tolerance of L-BFGS optimization. The smaller in magnitude this argument is the more precise the optimization algorithm will be.}

\item{test_if_global_optim}{a list containing two elements: \code{test} and \code{true_params}. \cr
(1) \code{test} is a logical scalar. It indicates whether the function should check whether the MLE is actually a global optimal point.
This is done by comparing the observed log likelihood at MLE vs. the log likelihood at the true parameter value. Hence, the second element of the list is \code{true_params}.
For this reason, it only makes sense to check when fitting simulated datasets where we would know the true parameter values. \cr
(2) \code{true_params} should be generated using the "LCTMC.simulate" package via the \code{gen_true_param(...)} function.}

\item{parallel_optim}{a list object telling the function whether parallel process should be used for the Step 2 of the initial value generation. \cr
The list should contain \strong{two} elements: \cr
(1) \code{run} a logical scalar, if TRUE then this function will use parallel processing. If FALSE, then the \code{cl} argument is ignored. \cr
(2) \code{cl} is an object obtained from the \code{parallel} package, for example \cr \code{cl = parallel::makeCluster(spec = 2)}}

\item{MyModelName}{a character scalar. Gives the current model fitting process a name. This name will be used when the function is logging the algorithm progress.}
}
\value{
A list object containing the 4 elements:
\itemize{
\item \strong{inits} a list object obtained from the \code{gen_inits_lctmc_3x3()} function
\item \strong{EM} a list object obtained from the \code{EM_lctmc_3x3()} function
\item \strong{SE} a list object obtained from the \code{get_SE_lctmc_3x3()} function
\item \strong{global_optim} a numeric scalar that indicates whether the MLE has converged to the global optimal point. See notes on the input argument for \code{test_if_global_optim}.
\item \strong{data} a data.frame object that is identical to the input argument, \code{data}.
\item \strong{K} an integer scalar that is identical to the input argument, \code{K}.
\item \strong{n_pars} an integer scalar that indicates the number of parameters estimated (total number of parameter minus number of constrained parameters).
\item \strong{X_names} a character vector equivalent to the input argument \code{X_names}
\item \strong{W_names} a character vector equivalent to the input argument \code{W_names}
\item \strong{run_time} a "difftime" object. Indicating the total algorithm run time.
}
}
\description{
A latent class CTMC (special 3x3 case) where we assume the data generating process is a CTMC when conditioned on a un-observed latent variable.
}
\note{
The model fitting process essentially breaks down into the following steps:
\enumerate{
\item data processing, formatting, scaling
\item generate initial values step 1, individualized fitting
\item generate initial values step 2, optimization on \eqn{log(P(Y))}
\item EM algorithm to obtain tighter estimate
\item hessian approximation for SE
\item re-scale parameters back to original scale
\item test for global optimal if specified to be tested
}
}
\examples{
## TO BE ADDED ##
}
