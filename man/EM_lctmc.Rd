% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/EM_lctmc.R
\name{EM_lctmc}
\alias{EM_lctmc}
\alias{EM_lctmc_2x2}
\alias{EM_lctmc_3x3}
\title{EM-algorithm for a latent CTMC model}
\usage{
EM_lctmc_2x2(
  EM_inits,
  df,
  df_Xmat,
  df_Wmat,
  df_dt,
  K,
  par_constraint,
  EM.maxit,
  ELL_diff.tol,
  LPY_diff.tol,
  par_diff.tol,
  LBFGSB.maxit,
  fnscale,
  factr,
  parallel_optim
)

EM_lctmc_3x3(
  EM_inits,
  df,
  df_Xmat,
  df_Wmat,
  df_dt,
  K,
  par_constraint,
  EM.maxit,
  ELL_diff.tol,
  LPY_diff.tol,
  par_diff.tol,
  LBFGSB.maxit,
  fnscale,
  factr,
  parallel_optim
)
}
\arguments{
\item{EM_inits}{a named numeric vector, where the names are the model parameter names. \cr
Use this argument to specified the initial values for the EM algorithm}

\item{df}{a data frame object containing row-wise transition data as binary variables. \cr
For example, if \code{trans.2_1} equals 1 then it means the observation was a transition from stage 2 to stage 1 within \code{df_dt} amount of time.}

\item{df_Xmat}{a matrix object housing the covariates that affect the CTMC portion of the model. \cr
This matrix should have the same number of rows as the data frame object, \code{df}}

\item{df_Wmat}{a matrix object housing the covariates that affect the latent classification part of the model. \cr
This matrix should have number of rows equal to unique number of individuals in the data frame object, \code{df}}

\item{df_dt}{a numeric vector housing the length of time interval between observations.
This vector's length should be equal to number of rows in the data frame object, \code{df}}

\item{K}{an integer scalar. Use this variable to tell the function how many latent classes there should be. \cr}

\item{par_constraint}{See documentation in \code{\link[=lctmc_2x2]{lctmc_2x2()}} or \code{\link[=lctmc_3x3]{lctmc_3x3()}}}

\item{EM.maxit}{a numeric scalar. Use this argument to specify the maximum iteration the EM algorithm.
Setting this variable too large will cause longer run time if optimal point is harder to reach. However, too low will lead to non-optimal points.
Typically, somewhere between 20-50 iterations is adequate depending on the problem.}

\item{ELL_diff.tol}{a numeric scalar that is greater than 0. This is the tolerance value for the expected conditional log-likelihood. \cr
The smaller this value, the more precise the estimate, however the longer run time will be needed.}

\item{LPY_diff.tol}{a numeric scalar that is greater than 0. This is the tolerance value for the log observed likelihood, \eqn{log(P(Y))}. \cr
The smaller this value, the more precise the estimate, however the longer run time will be needed.}

\item{par_diff.tol}{a numeric scalar that is greater than 0. This is the tolerance value for the changes in model parameter by iterations. \cr
The smaller this value, the more precise the estimate, however the longer run time will be needed.}

\item{LBFGSB.maxit}{the maximum number of iterations the algorithm will run before terminating.}

\item{fnscale}{a negative real number, this is used to scale the value of the objective function.
Setting it to negative implies that a maximization is being performed.}

\item{factr}{the tolerance parameter for algorithm convergence. The smaller the value, the better accuracy but also longer run time.}

\item{parallel_optim}{See documentation in \code{\link[=lctmc_2x2]{lctmc_2x2()}} or \code{\link[=lctmc_3x3]{lctmc_3x3()}}}
}
\value{
A list object containing as many elements as the number of EM iteration that were performed
Each element is a sub list object with the following elements:
\itemize{
\item \strong{iter} is a numeric scalar, indicating the count of current iteration
\item \strong{pars_value} is a named numeric vector for current iteration's estimated parameter values
\item \strong{ELL_value} is a numeric scalar for the current iteration's expected conditional log-likelihood evaluated at \code{pars_value}
\item \strong{LPY_value} is a numeric scalar for the current iteration's \eqn{log(P(Y))} evaluated at \code{pars_value}
\item \strong{par_diff.max} is a numeric scalar comparing previous iteration's \code{pars_value} and current iteration's \code{pars_value}. This value is maximum difference between the iterations. \cr
This is one of the values to evaluate EM algorithm's convergence. When \code{par_diff.max} < \code{par_diff.tol}, one of the convergence criteria is met.
\item \strong{ELL_diff} is a numeric scalar comparing previous iteration and current iteration's expected conditional log-likelihood. \cr
This is one of the values to evaluate EM algorithm's convergence. When \code{ELL_diff} < \code{ELL_diff.tol}, one of the convergence criteria is met.
\item \strong{LPY_diff} is a numeric scalar comparing previous iteration and current iteration's \eqn{log(P(Y))}. \cr
This is one of the values to evaluate EM algorithm's convergence. When \code{LPY_diff} < \code{LPY_diff.tol}, one of the convergence criteria is met.
\item \strong{time_at_finish} is a 'difftime' object telling the time from start of algorithm to current iteration
}
}
\description{
The EM algorithm attempts to maximize the likelihood by iteratively optimize the conditional expected log-likelihood.
This optimization approach is used to obtained the MLE of the latent class CTMC model.
Convergence for the EM algorithm is met when the improvement in the conditional expected log-likelihood does not improve further
}
\note{
This is the 4th step out of six of fitting a latent class CTMC model (i.e., the EM algorithm). \cr\cr
This function is actually the Expected Conditional Maximization (ECM) algorithm.
Within each EM step, subsets of parameters are optimize one set at a time, the number of ECM step is determined by \code{theta.names}. \cr
}
\examples{
# The example below demonstrates how to specify the 'lctmc' functions correctly
#   to perform the latent class CTMC model.
# -------------------------------------------------------------------------------------
# Both the 2x2 and 3x3 examples are listed below, however it should be noted
#   that the models may take a while to run (approx. 10-30min on a high spec laptop)
# -------------------------------------------------------------------------------------
# In the 2x2 model, we constrained the model so that the covariate effects on
#   the latent class probability are equal to 0.
# -------------------------------------------------------------------------------------
# In the 3x3 model, we left the model un-constrained.
# -------------------------------------------------------------------------------------
# In this code, we also use a for-loop to fit models with 2, 3, and 4 latent classes
#   the actual number of latent classes within these data sets is 2.
# -------------------------------------------------------------------------------------
# The model with the smallest BIC is the "best" model.
# -------------------------------------------------------------------------------------

\dontrun{
  ## this is a 2x2 example, with 3 latent classes
  data("example_df2x2", package = "LCTMC")
  ctrl_2x2 = LCTMC::create_controls(type = "2x2", data = example_df2x2)

  m2x2_list = list()
  for (k in 2:4) {
    m2x2 = LCTMC::lctmc_2x2(
      # data
      data = example_df2x2,
      # general model specification
      K = k,
      X_names = c('x0', 'x1', 'x2'),
      W_names = c('w0', 'w1', 'w2'),
      par_constraint = c(alpha1.1 = 0, alpha2.1 = 0),
      # misc.
      controls = ctrl_2x2,
      parallel_optim = list(
        run = TRUE, cl = parallel::makeCluster(spec = parallel::detectCores()-1)
      ),
      MyModelName = paste("My 2x2 (K=", k, ") model", sep = "")
    )

    m2x2_list[[paste("k", k, sep = "")]] = m2x2
  }

  BIC = sapply(
    X = m2x2_list[-1],
    FUN = function(x) {
      log_like = LCTMC::test_global_optim(m = x, data = example_df2x2)$L_mle
      k = x$n_pars
      n = nrow(example_df2x2) - length(unique(example_df2x2$id))
      -2*log_like + k*log(n)
    }
  )
  BIC
  which.min(BIC)


  # - # - # - # - # - # - # - # - #


  ## this is a 3x3 example, with 3 latent classes
  data("example_df3x3", package = "LCTMC")
  ctrl_3x3 = LCTMC::create_controls(type = "3x3", data = example_df3x3)

  m3x3_list = list()
  for (k in 2:4) {
    m3x3 = LCTMC::lctmc_3x3(
      # data
      data = example_df3x3,
      # general model specification
      K = k,
      X_names = c('x0', 'x1', 'x2'),
      W_names = c('w0', 'w1', 'w2'),
      par_constraint = NULL,
      # misc.
      controls = ctrl_3x3,
      parallel_optim = list(
        run = T,
        cl = parallel::makeCluster(spec = parallel::detectCores()-1)
      ),
      MyModelName = paste("My 3x3 (K=", k, ") model", sep = "")
    )

    m3x3_list[[paste("k", k, sep = "")]] = m3x3
  }

  BIC = sapply(
    X = m3x3_list[-1],
    FUN = function(x) {
      log_like = LCTMC::test_global_optim(m = x, data = example_df3x3)$L_mle
      k = x$n_pars
      n = nrow(example_df3x3) - length(unique(example_df3x3$id))
      -2*log_like + k*log(n)
    }
  )
  BIC
  which.min(BIC)
}
}
\seealso{
\code{\link[=lctmc_2x2]{lctmc_2x2()}}; \code{\link[=gen_inits02_lctmc_2x2]{gen_inits02_lctmc_2x2()}}; \code{\link[=get_SE_lctmc_2x2]{get_SE_lctmc_2x2()}}
}
